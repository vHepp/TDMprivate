{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed53c30c-2d01-444c-b379-9732bebc459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "\n",
    "from boto3.dynamodb.conditions import Key, Attr\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a10d4e7-3acb-4ce4-8c4e-0be6574438f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource( 'dynamodb' ) \n",
    "\n",
    "# ^^^ Initializes dynamodb for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bdf8654-0e79-42e7-a48f-29df1ca782de",
   "metadata": {},
   "outputs": [],
   "source": [
    "adspp_table = dynamodb.Table( 'ads_passenger_processed' ) \n",
    "\n",
    "# ^^^ Accesses the ads_passenger_processed table from Drive Ohio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c1bd65-1727-40bc-901f-667eed4ad991",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmID_df = pd.read_csv( '/home/rcoldren_linux/Desktop/Data/groupMetadataID_list_updated.csv' )\n",
    "\n",
    "# ^^^ Loads a .csv containing all 330 groupMetadataIDs (the unique IDs assigned to each of the 330 individual test drives done by \n",
    "#     Drive Ohio) into a Pandas data frame\n",
    "\n",
    "# The 'groupMetadataID_list_updated.csv' file is simply a renamed version of the 'ads_data_index.csv' file available in the\n",
    "# Students only -> Files -> Fall 2024 directory of Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd3b45ff-fc8a-4ec8-98e4-e41d480c9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmID_list = gmID_df[ 'groupMetadataID' ].tolist()\n",
    "\n",
    "# ^^^ Puts the 330 groupMetadataIDs in the Pandas data frame above into a list\n",
    "\n",
    "# This could also be a list of only a select few groupMetadataIDs; it does not have to be all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8180dfb0-c55d-4cb3-9feb-c04aa6874bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = [ '/apollo/canbus/chassis',\n",
    "              '/apollo/sensor/gnss/best_pose' ]\n",
    "\n",
    "# ^^^ A list of the topics one would like to pull out of the 'ads_passenger_processed' table for each groupMetadataID in \n",
    "#     'gmID_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dea98329-c5e5-45a7-9478-b9d387c75b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_path = '/home/rcoldren_linux/Desktop'\n",
    "\n",
    "# ^^^ The path to one's desktop in AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fd9cd07-97f0-4f2a-b2f4-3a225ea97cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 330 gmID out of 330\n",
      "Estimated Time Left: 0.0 min\n"
     ]
    }
   ],
   "source": [
    "delta_times = []\n",
    "\n",
    "# ^^^ Initializes a list for storing the amount of time it took to query for each groupMetadataID in 'gmID_list'\n",
    "\n",
    "count = 0\n",
    "\n",
    "# ^^^ Initializes a counting variable to indicate what groupMetadataID was just queried out of the N groupMetadataIDs in \n",
    "#     'gmID_list' in the loop below\n",
    "\n",
    "for gmID in gmID_list:\n",
    "\n",
    "    # ^^^ Iterates through each groupMetadataID in 'gmID_list'\n",
    "\n",
    "    time1 = time.time()\n",
    "\n",
    "    # ^^^ Records the time at the beginning of each groupMetadataID iteration, in sec\n",
    "\n",
    "    for topic in topic_list:\n",
    "\n",
    "        # ^^^ Iterates through each topic to be extracted (for the groupMetadataID in the first for loop's iteration) from the\n",
    "        #     topics in 'topic_list'\n",
    "\n",
    "        # vvv Creates the parameters for a query to extract the rows containing a particular groupMetadataID and topic (given by \n",
    "        #     the current 'gmID' and 'topic' of the two for loops) from the 'ads_passenger_processed' table\n",
    "\n",
    "        query_input = dict(\n",
    "                           IndexName = 'groupMetadataID-index',\n",
    "\n",
    "                           # ^^^ First, chooses the groupMetadataID as the index for the query\n",
    "                           \n",
    "                           FilterExpression = Attr( 'topic' ).eq( f'{ topic }' ),\n",
    "\n",
    "                           # ^^^ Third, tells the query to discard the rows missing the topic from the second for loop's current\n",
    "                           # iteration\n",
    "                           \n",
    "                           KeyConditionExpression = Key( 'groupMetadataID' ).eq( f'{ gmID }' ),\n",
    "\n",
    "                           # ^^^ Second, tells the query to extract the rows containing the groupMetadataID from the first for \n",
    "                           # loop's current iteration\n",
    "                          )\n",
    "\n",
    "        query_output = adspp_table.query( **query_input )\n",
    "\n",
    "        # ^^^ Performs the query on the 'ads_passenger_processed' table using the parameters set in 'query_input'\n",
    "\n",
    "        query_output_df = pd.DataFrame.from_dict( pd.json_normalize( query_output[ 'Items' ] ), orient = 'columns' )\n",
    "\n",
    "        # ^^^ Puts the rows extracted by the query into a Pandas data frame\n",
    "\n",
    "        while ( 'LastEvaluatedKey' in query_output.keys() ):\n",
    "\n",
    "            # ^^^ If the first query stopped prematurely due to reaching the 1 MB limit, starts a while loop that continues to \n",
    "            #     query the 'ads_passenger_processed' table until it is complete\n",
    "\n",
    "            query_input[ 'ExclusiveStartKey' ] = query_output[ 'LastEvaluatedKey' ]\n",
    "\n",
    "            # ^^^ Slightly modifies the query parameters to tell the next query to start where the last query stopped \n",
    "\n",
    "            query_output = adspp_table.query( **query_input )\n",
    "\n",
    "            # ^^^ Performs the query that continues where the last one left off\n",
    "\n",
    "            temp_df = pd.DataFrame.from_dict( pd.json_normalize( query_output[ 'Items' ] ), orient = 'columns' )\n",
    "\n",
    "            # ^^^ Puts the rows extracted by the continuation query into a temporary Pandas data frame\n",
    "\n",
    "            query_output_df = pd.concat( [ query_output_df, temp_df ] )\n",
    "\n",
    "            # ^^^ Concatenates the rows extracted by the continuation query (in the temporary data frame) to the\n",
    "            #     Pandas data frame that will hold all of the query data in the end\n",
    "\n",
    "        dir_friendly_topic = topic.replace( '/', '_' )\n",
    "\n",
    "        # ^^^ Creates a slightly modified version of the topic of the second for loop's current iteration so it is able to be used\n",
    "        #     as part of the name of a folder (forward slashes are not allowed in folder names due to causing issues with their \n",
    "        #     path)\n",
    "\n",
    "        if not os.path.exists( f'{ desktop_path }/Raw_Data/{ gmID }/{ dir_friendly_topic }' ):\n",
    "        \n",
    "            os.makedirs( f'{ desktop_path }/Raw_Data/{ gmID }/{ dir_friendly_topic }' )\n",
    "\n",
    "        # ^^^ Creates a directory structure (starting at one's desktop in AWS) to store the fully extracted current topic data\n",
    "        #     for the current groupMetadataID, if it does exist already\n",
    "\n",
    "        csv_name = gmID + dir_friendly_topic\n",
    "\n",
    "        # ^^^ Creates a name for the .csv file that will hold the extracted current topic data for the current groupMetadataID\n",
    "\n",
    "        query_output_df.to_csv( f'{ desktop_path }/Raw_Data/{ gmID }/{ dir_friendly_topic }/{ csv_name }.csv', index = False )\n",
    "\n",
    "        # ^^^ Saves the fully extracted current topic data for the current groupMetadataID as a .csv file in the aforementioned\n",
    "        #     directory structure\n",
    "\n",
    "    time2 = time.time()\n",
    "\n",
    "    # ^^^ Records the time at the (approximate) end of each groupMetadataID iteration, in sec\n",
    "\n",
    "    # vvv Indicates that the (count + 1)th groupMetadataID was just queried\n",
    "    \n",
    "    count = count + 1\n",
    "\n",
    "    delta_time = ( time2 - time1 ) / 60\n",
    "\n",
    "    # ^^^ Calculates how long it took to query for the current iteration's groupMetadataID's requested topics (in min)\n",
    "\n",
    "    delta_times.append( delta_time )\n",
    "\n",
    "    # ^^^ Appends the just calculated 'delta_time' to the list 'delta_times', to keep track of how long the current iteration took,\n",
    "    #     as well as how long all the previous iterations took\n",
    "\n",
    "    avg_delta_time = sum( delta_times ) / count\n",
    "\n",
    "    # ^^^ Calculates the average time to complete one iteration (in min) given how long the current and previous iterations took\n",
    "\n",
    "    est_time_left = avg_delta_time * ( len( gmID_list ) - count )\n",
    "\n",
    "    # ^^^ Assumming the remaining iterations take exactly as long as the 'avg_delta_time', calculates the amount of time remaining\n",
    "    #     until all the groupMetadataIDs in 'gmID_list' have been queried for (in min)\n",
    "\n",
    "    print( f'Progress: { count } gmID out of { len( gmID_list ) }' )\n",
    "    print( f'Estimated Time Left: { est_time_left } min' )\n",
    "\n",
    "    # ^^^ Prints how many groupMetadataIDs have been queried for so far out of the total number of groupMetadataIDs in 'gmID_list'\n",
    "    #     and how much time is estimated to be left until all the groupMetadataIDs in 'gmID_list' have been queried for (in min)\n",
    "\n",
    "    clear_output( wait = True )\n",
    "\n",
    "    # ^^^ Replaces the previous printed progress indicator with a new one (if a new is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6813380-8333-4ab5-9a6f-a5939da0458b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
